---
title: "Assignment#4 - ML regression and BL regression models "
author: "Douglas Barley, Ethan Haley, Isabel Magnus, John Mazon, Vinayak Kamath, Arushi Arora"
date: "11/07/2021"
output:
  html_document: 
    toc: true
    toc-title: "Assignment 4 - Multiple linear regression and Binary logistic regression models  "
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: darkly
    highlight: pygments
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
if (!require("ggplot2",character.only = TRUE)) (install.packages("ggplot2",dep=TRUE))
if (!require("knitr",character.only = TRUE)) (install.packages("knitr",dep=TRUE))
if (!require("xtable",character.only = TRUE)) (install.packages("xtable",dep=TRUE))
if (!require("dplyr",character.only = TRUE)) (install.packages("dplyr",dep=TRUE))
if (!require("stringr",character.only = TRUE)) (install.packages("stringr",dep=TRUE))
if (!require("Hmisc",character.only = TRUE)) (install.packages("Hmisc",dep=TRUE))
library(ggplot2)
library(knitr)
library(xtable)
library(dplyr)
library(stringr)
library(tidyverse)
library(dplyr)
library(ROCR)
library(Hmisc)
library(corrplot)
library(MASS)
library(caret)
library(data.table)
require(data.table)
require(car)
require(corrgram)
require(ggplot2)
```

 DATA 621 – Business Analytics and Data Mining
 

# Overview  
In this homework assignment, you will explore, analyze and model a data set containing approximately 8000 
records  representing  a  customer  at  an  auto  insurance  company.  Each  record  has  two  response  variables.  The 
first  response  variable, TARGET_FLAG, is a 1 or a 0. A “1” means that the person was in a car crash. A zero 
means that the person was not in a car crash. The second response variable is TARGET_AMT. This value is zero 
if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero. 
 
Your objective is to build multiple linear regression and binary logistic regression models on the training data 
to predict the probability that a person will crash their car and also the amount of money it will cost if the person 
does crash their car. You can only use the variables given to you (or variables that you derive from the variables 
provided). 

- **INDEX**:  Identification Variable (do not use)
- **TARGET_FLAG**: Was Car in a crash? 1=YES 0=NO None
- **TARGET_AMT**: If car was in a crash, what was the cost None
- **AGE**: Age of Driver Very young people tend to be risky. Maybe very old people also.
- **BLUEBOOK**: Value of Vehicle Unknown effect on probability of collision, but probably effect the payout if there is a crash
- **CAR_AGE**: Vehicle Age Unknown effect on probability of collision, but probably effect the payout if there is a crash
- **CAR_TYPE**: Type of Car Unknown effect on probability of collision, but probably effect the payout if there is a crash
- **CAR_USE**: Vehicle Use Commercial vehicles are driven more, so might increase probability of collision
- **CLM_FREQ**: # Claims (Past 5 Years) The more claims you filed in the past, the more you are likely to file in the future
- **EDUCATION**: Max Education Level Unknown effect, but in theory more educated people tend to drive more safely
- **HOMEKIDS**: # Children at Home Unknown effect
- **HOME_VAL**: Home Value In theory, home owners tend to drive more responsibly
- **INCOME**: Income In theory, rich people tend to get into fewer crashes
- **JOB**: Job Category In theory, white collar jobs tend to be safer
- **KIDSDRIV**: # Driving Children When teenagers drive your car, you are more likely to get into crashes
- **MSTATUS**: Marital Status In theory, married people drive more safely
- **MVR_PTS**: Motor Vehicle Record Points If you get lots of traffic tickets, you tend to get into more crashes
- **OLDCLAIM**: Total Claims (Past 5 Years) If your total payout over the past five years was high, this suggests future payouts will be high
- **PARENT1**: Single Parent Unknown effect
- **RED_CAR**: A Red Car Urban legend says that red cars (especially red sports cars) are more risky. Is that true?
- **REVOKED**: License Revoked (Past 7 Years) If your license was revoked in the past 7 years, you probably are a more risky driver.
- **SEX**: Gender Urban legend says that women have less crashes then men. Is that true?
- **TIF**: Time in Force People who have been customers for a long time are usually more safe.
- **TRAVTIME**: Distance to Work Long drives to work usually suggest greater risk
- **URBANICITY**: Home/Work Area Unknown
- **YOJ**: Years on Job People who stay at a job for a long time are usually more safe

# DATA EXPLORATION
Describe the size and the variables in the  insurance training data set. Consider that too much detail will cause a 
manager to lose interest while too little detail will make the manager consider that you aren’t doing your job. Some 
suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. 
You should have your own thoughts on what to tell the boss. These are just ideas. 
a. Mean / Standard Deviation / Median 
b. Bar Chart or Box Plot of the data 
c. Is the data correlated to the target variable (or to other variables?) 
d. Are any of the variables missing and need to be imputed “fixed”?





# DATA PREPARATION
Describe how you have transformed the data by changing the original variables or creating new variables. If you 
did transform the data or create new variables, discuss why you did this. Here are some possible transformations. 
 
a. Fix missing values (maybe with a Mean or Median value) 
b. Create flags to suggest if a variable was missing 
c. Transform data by putting it into buckets 
d. Mathematical transforms such as log or square root (or use Box-Cox) 
e. Combine variables (such as ratios or adding or multiplying) to create new variables

### Load datasets

```{r reading data}
ins_train_df <- read.csv("https://raw.githubusercontent.com/johnm1990/msds-621/main/insurance_training_data.csv")
ins_eval_df <- read.csv("https://raw.githubusercontent.com/johnm1990/msds-621/main/insurance-evaluation-data.csv")
```

### inspect values

```{r}
summary(ins_train_df)
```

```{r}
#before whole list of columns telling class, now showing measure

ins_train_df <- as.data.frame(lapply(ins_train_df, gsub, pattern='z_', replacement=''))
ins_eval_df <- as.data.frame(lapply(ins_eval_df, gsub, pattern='z_', replacement=''))
cols.num <- c("TARGET_FLAG",
"TARGET_AMT",
"AGE",
"YOJ",
"TRAVTIME",
"TIF",
"CLM_FREQ",
"MVR_PTS",
"CAR_AGE",
"KIDSDRIV",
"HOMEKIDS"
)
ins_train_df[cols.num] <- sapply(ins_train_df[cols.num],as.numeric)
ins_eval_df[cols.num] <- sapply(ins_eval_df[cols.num],as.numeric)


#do not need, the function already handled
#ins_train_df <- lapply(ins_train_df, gsub, pattern='$', replacement='')
#ins_eval_df <- lapply(ins_eval_df, gsub, pattern='$', replacement='')

#ins_train_df <- lapply(ins_train_df, gsub, pattern=',', replacement='')
#ins_eval_df <- lapply(ins_eval_df, gsub, pattern=',', replacement='')

ins_eval_df$SEX <- factor(ins_eval_df$SEX)
ins_train_df$SEX <- factor(ins_train_df$SEX)
ins_eval_df$JOB <- factor(ins_eval_df$JOB)
ins_train_df$JOB <- factor(ins_train_df$JOB)
ins_eval_df$CAR_USE <- factor(ins_eval_df$CAR_USE)
ins_train_df$CAR_USE <- factor(ins_train_df$CAR_USE)
ins_eval_df$CAR_TYPE <- factor(ins_eval_df$CAR_TYPE)
ins_train_df$CAR_TYPE <- factor(ins_train_df$CAR_TYPE)
ins_eval_df$URBANICITY <- factor(ins_eval_df$URBANICITY)
ins_train_df$URBANICITY <- factor(ins_train_df$URBANICITY)

ins_eval_df$EDUCATION <- factor(ins_eval_df$EDUCATION,
                                   levels = c("<High School", "High School",
                                               "Bachelors", "Masters", "PhD"),
                                    ordered = T)
ins_train_df$EDUCATION <- factor(ins_train_df$EDUCATION,
                                   levels = c("<High School", "High School",
                                               "Bachelors", "Masters", "PhD"),
                                    ordered = T)
```



#### Some columns should be numbers but aren't

```{r}
#print first six values
head(ins_train_df$BLUEBOOK)
typeof(ins_train_df$BLUEBOOK)
```


```{r}
head(ins_train_df$INCOME)
typeof(ins_train_df$INCOME)
```

```{r}
head(ins_train_df$HOME_VAL)
typeof(ins_train_df$HOME_VAL)
```

```{r}
head(ins_train_df$OLDCLAIM)
typeof(ins_train_df$OLDCLAIM)
```

#### convert strings to integers, filling blanks as 0

#need to check for decimals, convert to integer.No decimals.
```{r}

head(ins_train_df$INCOME)

#change it to as.numeric from original (as.integer) ***overwrites existing character type
dollars <- function(n){
  as.numeric(paste0('0', str_remove_all(n, '[,$]')))  # add leading zero for blanks
}
dollars(ins_train_df$INCOME[1:11])
```

```{r}
#converting to dollars of blue blook

ins_eval_df$BLUEBOOK = dollars(ins_eval_df$BLUEBOOK)
ins_train_df$BLUEBOOK = dollars(ins_train_df$BLUEBOOK)
ins_eval_df$HOME_VAL = dollars(ins_eval_df$HOME_VAL)
ins_train_df$HOME_VAL = dollars(ins_train_df$HOME_VAL)
ins_eval_df$INCOME = dollars(ins_eval_df$INCOME)
ins_train_df$INCOME = dollars(ins_train_df$INCOME)
ins_eval_df$OLDCLAIM = dollars(ins_eval_df$OLDCLAIM)
ins_train_df$OLDCLAIM = dollars(ins_train_df$OLDCLAIM)
```

#### Inspect more features

```{r}
#change to head
ins_train_df$PARENT1[1:11]
ins_train_df$MSTATUS[1:11]
ins_train_df$SEX[1:11]
ins_train_df$EDUCATION[1:11]
ins_train_df$JOB[1:11]
ins_train_df$CAR_USE[1:11]
ins_train_df$CAR_TYPE[1:11]
ins_train_df$REVOKED[1:11]
ins_train_df$URBANICITY[1:11]
ins_train_df$RED_CAR[1:11]

table(ins_train_df$URBANICITY)
```
#### Turn boolean strings into booleans

```{r}
#not necessary
#changes to logical type

table(ins_train_df$REVOKED)

ins_train_df$REVOKED = tolower(ins_train_df$REVOKED)=='yes'
ins_eval_df$REVOKED = tolower(ins_eval_df$REVOKED)=='yes'
ins_train_df$PARENT1 = tolower(ins_train_df$PARENT1)=='yes'
ins_eval_df$PARENT1 = tolower(ins_eval_df$PARENT1)=='yes'
ins_train_df$RED_CAR = tolower(ins_train_df$RED_CAR)=='yes'
ins_eval_df$RED_CAR = tolower(ins_eval_df$RED_CAR)=='yes'
ins_train_df$MSTATUS = tolower(ins_train_df$MSTATUS)=='yes'
ins_eval_df$MSTATUS = tolower(ins_eval_df$MSTATUS)=='yes'
```



```{r}
summary(ins_train_df)
ins_train_df$INCOME <- as.numeric(ins_train_df$INCOME)
typeof(ins_train_df$INCOME)
head(ins_train_df$INCOME)
```






```{r}
#x include all numeric column
#summaries for mean
#y %>% 
#             group_by(hour) %>% 
#             mutate(profit= ifelse(is.na(profit), mean(profit, na.rm=TRUE), profit))
x <- ins_train_df %>% 
  dplyr::select(where(is.numeric))
kable(sapply(x, function(x) c( "Stand dev" = sd(x), 
                         "Mean"= mean(x,na.rm=TRUE),
                         "n" = length(x),
                         "Median" = median(x,na.rm = TRUE),
                         "CoeffofVariation" = sd(x)/mean(x,na.rm=TRUE),
                         "Minimum" = min(x),
                         "Maximun" = max(x),
                         "Upper Quantile" = quantile(x,1,na.rm = TRUE),
                         "LowerQuartile" = quantile(x,0,na.rm = TRUE)
                    )
)
)

```


### BRAINSTORM





# BUILD MODELS 






# SELECT MODELS


 

